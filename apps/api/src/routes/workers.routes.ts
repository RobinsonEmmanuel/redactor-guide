import { FastifyInstance } from 'fastify';
import { ObjectId } from 'mongodb';
import { PageRedactionService } from '../services/page-redaction.service';
import { JsonTranslatorService } from '../services/json-translator.service';

export async function workersRoutes(fastify: FastifyInstance) {
  /**
   * POST /workers/generate-page-content
   * Worker pour g√©n√©rer le contenu d'une page via IA
   * Appel√© par QStash de mani√®re asynchrone
   */
  fastify.post('/workers/generate-page-content', async (request, reply) => {
    const db = request.server.container.db;
    const { guideId, pageId } = request.body as { guideId: string; pageId: string };

    try {
      console.log(`üöÄ [WORKER] G√©n√©ration contenu page ${pageId}`);

      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY non configur√©e');
      }

      // G√©n√©rer le contenu via IA (avec retry automatique int√©gr√©)
      const redactionService = new PageRedactionService(db, openaiApiKey);
      const result = await redactionService.generatePageContent(guideId, pageId);

      // D√©terminer le statut √©ditorial selon le r√©sultat
      let statutEditorial = 'draft';
      let commentaire: string | undefined;

      if (result.status === 'success') {
        statutEditorial = 'generee_ia';
        commentaire = result.retryCount && result.retryCount > 0
          ? `G√©n√©r√© avec succ√®s apr√®s ${result.retryCount} tentative(s)`
          : undefined;
        console.log(`‚úÖ [WORKER] G√©n√©ration r√©ussie apr√®s ${result.retryCount || 0} retry(s)`);
      } else if (result.validationErrors && result.validationErrors.length > 0) {
        // Validation √©chou√©e apr√®s retries
        statutEditorial = 'non_conforme';
        const failedFieldsSummary = result.validationErrors
          .map((e) => `${e.field} (${e.errors.length} erreur(s))`)
          .join(', ');
        commentaire = `Validation √©chou√©e apr√®s ${result.retryCount || 0} tentative(s): ${failedFieldsSummary}`;
        console.error(`‚ùå [WORKER] Validation non conforme:`, commentaire);
      } else {
        // Autre erreur
        statutEditorial = 'non_conforme';
        commentaire = `Erreur IA: ${result.error || 'Erreur inconnue'}`;
        console.error(`‚ùå [WORKER] Erreur g√©n√©ration:`, commentaire);
      }

      // Sauvegarder le contenu g√©n√©r√© (m√™me si validation √©choue, pour permettre √©dition manuelle)
      await db.collection('pages').updateOne(
        { _id: new ObjectId(pageId) },
        { 
          $set: { 
            content: result.content,
            statut_editorial: statutEditorial,
            ...(commentaire && { commentaire_interne: commentaire }),
            updated_at: new Date().toISOString() 
          } 
        }
      );

      console.log(`‚úÖ [WORKER] Contenu sauvegard√© pour page ${pageId} (statut: ${statutEditorial})`);

      return reply.send({ 
        success: result.status === 'success', 
        pageId,
        fieldsGenerated: Object.keys(result.content).length,
        statutEditorial,
        retryCount: result.retryCount || 0,
        validationErrors: result.validationErrors
      });
    } catch (error: any) {
      console.error(`‚ùå [WORKER] Erreur fatale:`, error);
      
      // Marquer la page en erreur
      try {
        await db.collection('pages').updateOne(
          { _id: new ObjectId(pageId) },
          { 
            $set: { 
              statut_editorial: 'non_conforme',
              commentaire_interne: `Erreur worker: ${error.message}`,
              updated_at: new Date().toISOString() 
            } 
          }
        );
      } catch (dbError) {
        console.error('Erreur mise √† jour statut:', dbError);
      }

      return reply.status(500).send({ 
        error: 'Erreur lors de la g√©n√©ration',
        details: error.message 
      });
    }
  });

  /**
   * POST /workers/generate-pois
   * Worker pour g√©n√©rer les POIs depuis les articles WordPress via IA
   * Traitement par batch pour un recensement exhaustif, suivi d'un appel de d√©duplication.
   * Appel√© par QStash de mani√®re asynchrone
   */
  fastify.post('/workers/generate-pois', async (request, reply) => {
    const db = request.server.container.db;
    const { guideId, jobId } = request.body as { guideId: string; jobId: string };

    try {
      console.log(`üöÄ [WORKER] G√©n√©ration POIs par batch pour guide ${guideId}`);

      // Garde anti-doublon : refuser si un autre job est d√©j√† en cours pour ce guide
      const existingProcessing = await db.collection('pois_generation_jobs').findOne({
        guide_id: guideId,
        status: 'processing',
        _id: { $ne: new ObjectId(jobId) },
        // Ignorer les jobs bloqu√©s depuis plus de 30 minutes
        updated_at: { $gte: new Date(Date.now() - 30 * 60 * 1000) },
      });
      if (existingProcessing) {
        console.warn(`‚ö†Ô∏è [WORKER] Job ${existingProcessing._id} d√©j√† en cours pour guide ${guideId} ‚Äî abandon du doublon ${jobId}`);
        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { status: 'failed', error: 'Doublon : un job est d√©j√† en cours', updated_at: new Date() } }
        );
        return reply.send({ success: false, reason: 'duplicate' });
      }

      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { $set: { status: 'processing', updated_at: new Date() } }
      );

      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY non configur√©e');
      }

      const { OpenAIService } = await import('../services/openai.service');

      const openaiService = new OpenAIService({
        apiKey: openaiApiKey,
        model: 'gpt-5-mini',
        reasoningEffort: 'low',
      });

      // 1. Charger le guide
      const guide = await db.collection('guides').findOne({ _id: new ObjectId(guideId) });
      if (!guide) throw new Error('Guide non trouv√©');

      const destination: string = guide.destination;
      if (!destination) throw new Error('Aucune destination d√©finie pour ce guide');

      // 2. R√©cup√©rer les articles WordPress filtr√©s par destination
      const destinationFilter = { categories: { $regex: destination, $options: 'i' } };

      const articles = await db
        .collection('articles_raw')
        .find(destinationFilter)
        .project({ title: 1, slug: 1, markdown: 1, url: 1 })
        .toArray();

      if (articles.length === 0) {
        throw new Error(`Aucun article WordPress trouv√© pour la destination "${destination}"`);
      }

      console.log(`üìö ${articles.length} articles charg√©s pour "${destination}"`);

      // 3. Charger les prompts depuis la DB par leur ID unique
      const PROMPT_ID_EXTRACTION = process.env.PROMPT_ID_POI_EXTRACTION ?? 'prompt_1770544848350_9j5m305ukj';
      const PROMPT_ID_DEDUP      = process.env.PROMPT_ID_POI_DEDUP      ?? 'deduplication_POI_24022026';

      const promptExtractionDoc = await db.collection('prompts').findOne({ prompt_id: PROMPT_ID_EXTRACTION });
      if (!promptExtractionDoc) {
        throw new Error(`Prompt d'extraction POI non trouv√© (id: ${PROMPT_ID_EXTRACTION})`);
      }
      console.log(`üìã Prompt extraction: ${promptExtractionDoc.prompt_nom || promptExtractionDoc.prompt_id}`);

      // Prompt de d√©duplication (optionnel ‚Äî fallback int√©gr√© si absent)
      const promptDedupDoc = await db.collection('prompts').findOne({ prompt_id: PROMPT_ID_DEDUP });
      if (promptDedupDoc) {
        console.log(`üìã Prompt d√©dup: ${promptDedupDoc.prompt_nom || promptDedupDoc.prompt_id}`);
      } else {
        console.log(`üìã Prompt d√©dup: id "${PROMPT_ID_DEDUP}" non trouv√©, utilisation du prompt par d√©faut`);
      }

      // ‚îÄ‚îÄ‚îÄ Helper : extraction H2/H3 (utilis√© pour les articles multi-POI) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

      function extractHeadings(markdown: string): string[] {
        return markdown
          .split('\n')
          .filter(line => /^#{2,3}\s/.test(line))
          .map(line => line.replace(/^#{2,3}\s+/, '').trim())
          .filter(h => h.length > 2);
      }

      // ‚îÄ‚îÄ‚îÄ 4. Classification IA des articles ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      // Payload ultra-l√©ger : on envoie uniquement les titres

      console.log(`ü§ñ Classification IA de ${(articles as any[]).length} articles...`);

      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { $set: { progress: `Classification IA de ${(articles as any[]).length} articles...`, updated_at: new Date() } }
      );

      const articleTitlesList = (articles as any[])
        .map((a: any, i: number) => `${i}. ${a.title}`)
        .join('\n');

      const classificationSystemPrompt = `Tu es un expert en contenu touristique. Classifie chaque article dans l'une de ces 3 cat√©gories :

- "mono" : l'article est enti√®rement consacr√© √† UN SEUL lieu touristique pr√©cis et localisable (une plage sp√©cifique, un site naturel, un monument, un village, une piscine naturelle, un mirador, un belv√©d√®re, etc.). Le nom du lieu principal est dans le titre.
- "multi" : l'article pr√©sente ou liste PLUSIEURS lieux touristiques distincts (guides "que faire √† X", tops N lieux, itin√©raires, listes de plages/jardins/villages, "pourquoi visiter", etc.)
- "exclude" : l'article ne g√©n√®re pas de POI pertinent pour un guide touristique. Exemples : h√¥tels/h√©bergements/apparthotels, transport/location de voiture/comment se d√©placer, m√©t√©o/saisons/quand partir/combien de jours, guides pratiques g√©n√©raux, comparaisons de destinations.

Pour les articles "mono", indique √©galement le poi_name : le nom propre du lieu, sans les suffixes descriptifs comme "conseils + photos", "avis + photos", etc.

Retourne STRICTEMENT un objet JSON valide, sans texte additionnel :
{ "classifications": [{ "index": 0, "type": "mono|multi|exclude", "poi_name": "string ou null", "reason": "explication courte" }] }`;

      let aiClassifications: Array<{ index: number; type: 'mono' | 'multi' | 'exclude'; poi_name: string | null; reason: string }> = [];

      try {
        const classifResult = await openaiService.generateJSON(
          `${classificationSystemPrompt}\n\nArticles √† classifier :\n${articleTitlesList}`,
          8000
        );
        aiClassifications = (classifResult as any).classifications || [];
        console.log(`‚úÖ Classification IA : ${aiClassifications.length} articles classifi√©s`);
      } catch (err: any) {
        console.error(`‚ùå Erreur classification IA : ${err.message} ‚Äî fallback classification "multi" pour tous`);
        aiClassifications = (articles as any[]).map((_: any, i: number) => ({
          index: i, type: 'multi' as const, poi_name: null, reason: 'fallback (erreur IA)',
        }));
      }

      const monoArticles: any[] = [];
      const multiArticles: any[] = [];
      const excludedArticles: any[] = [];
      const classificationLog: any[] = [];

      for (let i = 0; i < (articles as any[]).length; i++) {
        const article = (articles as any[])[i];
        const classif = aiClassifications.find(c => c.index === i) || { type: 'multi', poi_name: null, reason: 'non classifi√©' };
        const headings = classif.type === 'multi' ? extractHeadings(article.markdown || '') : [];

        classificationLog.push({
          title: article.title,
          url: article.url || article.slug,
          type: classif.type,
          reason: classif.reason,
          poiName: classif.poi_name || undefined,
          headingCount: headings.length || undefined,
        });

        if (classif.type === 'mono') {
          monoArticles.push({ ...article, _poi_name: classif.poi_name || article.title, _classification: classif });
        } else if (classif.type === 'multi') {
          multiArticles.push({ ...article, _headings: headings, _classification: classif });
        } else {
          excludedArticles.push({ ...article, _classification: classif });
        }
      }

      console.log(`üìä Classification: ${monoArticles.length} mono-POI, ${multiArticles.length} multi-POI, ${excludedArticles.length} exclus`);

      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        {
          $set: {
            classification_log: classificationLog,
            mono_count: monoArticles.length,
            multi_count: multiArticles.length,
            excluded_count: excludedArticles.length,
            updated_at: new Date(),
          },
        }
      );

      const allRawPois: any[] = [];
      const previewBatches: any[] = [];

      // ‚îÄ‚îÄ‚îÄ 5a. Articles mono-POI : extraction directe, sans IA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

      for (const article of monoArticles) {
        const poiName = article._poi_name || article.title;
        allRawPois.push({
          poi_id: poiName.toLowerCase().replace(/[^a-z0-9]+/g, '_').replace(/^_|_$/g, ''),
          nom: poiName,
          type: 'site_naturel',
          article_source: article.title,
          url_source: article.url || article.slug,
          mentions: 'principale',
          raison_selection: `Article d√©di√© : "${article.title}"`,
          autres_articles_mentions: [],
          _extraction_mode: 'mono',
        });
      }

      console.log(`‚úÖ Mono-POI: ${monoArticles.length} POIs extraits directement`);

      // Sauvegarde interm√©diaire des mono-POIs
      if (monoArticles.length > 0) {
        previewBatches.push({
          batch_num: 0,
          total_batches: 0,
          label: `${monoArticles.length} articles mono-POI (extraction directe)`,
          articles: monoArticles.map((a: any) => ({ title: a.title, url: a.url || a.slug })),
          pois: allRawPois.filter(p => p._extraction_mode === 'mono'),
          is_mono_batch: true,
        });
        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { preview_pois: [...allRawPois], preview_batches: [...previewBatches], updated_at: new Date() } }
        );
      }

      // ‚îÄ‚îÄ‚îÄ 5b. Articles multi-POI : extraction par batch via IA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

      /**
       * Normalise la r√©ponse IA quel que soit le format retourn√© :
       * { pois: [...] }, { articles: [{ slug, pois: [...] }] }, { "slug": [...] }, [...]
       */
      function normalizePoisFromResult(result: any): any[] | null {
        if (!result || typeof result !== 'object') return null;
        if (Array.isArray(result.pois)) return result.pois;
        if (Array.isArray(result)) return result;
        if (Array.isArray(result.articles)) {
          const flat: any[] = [];
          for (const art of result.articles) {
            const subPois = art.pois || art.lieux || art.points_of_interest;
            if (Array.isArray(subPois)) {
              subPois.forEach((p: any) => flat.push({
                ...p,
                article_source: p.article_source || art.title || art.slug || '',
                url_source: p.url_source || art.url || art.slug || '',
              }));
            }
          }
          return flat.length > 0 ? flat : [];
        }
        const values = Object.values(result);
        if (values.length > 0 && values.every(v => Array.isArray(v))) {
          const flat: any[] = [];
          for (const [slug, pois] of Object.entries(result)) {
            (pois as any[]).forEach((p: any) => flat.push({
              ...p,
              article_source: p.article_source || slug,
              url_source: p.url_source || slug,
            }));
          }
          return flat.length > 0 ? flat : [];
        }
        return null;
      }

      const BATCH_SIZE = 5;
      const total = multiArticles.length;
      const totalBatches = Math.ceil(total / BATCH_SIZE);

      console.log(`üìä Multi-POI: ${total} articles ‚Üí ${totalBatches} batches de ${BATCH_SIZE}`);

      for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
        const batchNum = batchIdx + 1;

        // V√©rifier √† chaque batch si le job a √©t√© annul√©
        const currentJob = await db.collection('pois_generation_jobs').findOne({ _id: new ObjectId(jobId) });
        if (!currentJob || currentJob.status === 'cancelled') {
          console.log(`üõë [WORKER] Job ${jobId} annul√© ‚Äî arr√™t √† batch ${batchNum}/${totalBatches}`);
          return reply.send({ success: false, reason: 'cancelled' });
        }

        const batchArticles = multiArticles.slice(batchIdx * BATCH_SIZE, (batchIdx + 1) * BATCH_SIZE) as any[];
        const firstArticleNum = batchIdx * BATCH_SIZE + 1;

        console.log(`üîÑ Batch ${batchNum}/${totalBatches} ‚Äî articles ${firstArticleNum}-${firstArticleNum + batchArticles.length - 1}`);

        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { status: 'processing', progress: `Batch ${batchNum}/${totalBatches}`, updated_at: new Date() } }
        );

        // Filtrer les articles vides
        const validArticles = batchArticles.filter((a: any) => (a.markdown || '').trim());
        if (validArticles.length === 0) {
          console.log(`  ‚ö†Ô∏è Batch ${batchNum}: tous les articles sont vides, ignor√©`);
          continue;
        }


        // Construire un article_source lookup pour la correction post-r√©ponse
        const articleByTitle: Record<string, any> = {};
        const articleByUrl: Record<string, any> = {};
        for (const a of validArticles) {
          articleByTitle[a.title.toLowerCase()] = a;
          if (a.url) articleByUrl[a.url] = a;
          if (a.slug) articleByUrl[a.slug] = a;
        }

        // Prompt d√©di√© H2/H3 : plus fiable que d'injecter les headings dans le prompt utilisateur
        // qui attend un contenu d'article complet.
        const h2h3PerArticle = validArticles.map((a: any, idx: number) => {
          const headings = extractHeadings(a.markdown || '');
          // Filtrer les headings g√©n√©riques (intro, conseils, FAQ, etc.)
          const GENERIC = /^(introduction|pr√©sentation|conseils|conseil|pratique|infos?|FAQ|r√©sum√©|conclusion|en bref|contact|acc√®s|horaire|tarif|prix|comment|pourquoi|o√π|quand|notre avis|notre s√©lection|pour aller plus loin|autres|suite)/i;
          const poiCandidates = headings.filter(h => !GENERIC.test(h.trim()) && h.trim().length > 3);
          return `Article ${idx + 1}: "${a.title}" (URL: ${a.url || a.slug})\nTitres H2/H3 candidats POI:\n${poiCandidates.map(h => `  ‚Ä¢ ${h}`).join('\n') || '  (aucun titre POI identifi√©)'}`;
        }).join('\n\n');

        const extractionPrompt = `Tu es un expert en s√©lection touristique pour des guides de voyage.

Destination : ${destination}
Site : ${guide.wpConfig?.siteUrl || ''}

Pour chaque article ci-dessous, extrais UNIQUEMENT les lieux touristiques r√©els (POI) √† partir des titres H2/H3.

R√®gles de s√©lection :
- Un POI est un lieu pr√©cis et localisable : mus√©e, site naturel, plage, village, monument, panorama, jardin, etc.
- Les titres num√©rot√©s ("1. Nom du lieu", "2. Nom du lieu") sont g√©n√©ralement des POIs
- IGNORER les sections g√©n√©riques : introduction, conseils pratiques, FAQ, tarifs, horaires, "pourquoi visiter", "notre avis"
- IGNORER les h√©bergements et restaurants
- article_source = titre de l'article dont est issu le POI
- url_source = URL de l'article source

Articles √† traiter :
${h2h3PerArticle}

Exclusions strictes : h√¥tels, h√©bergements, restaurants, bars, commerces.

Retourne STRICTEMENT un JSON valide sans texte additionnel :
{ "pois": [ { "poi_id": "slug_unique", "nom": "Nom du POI", "type": "mus√©e|site_culturel|village|ville|plage|site_naturel|panorama|quartier|autre", "article_source": "titre de l'article", "url_source": "url de l'article", "mentions": "principale", "raison_selection": "max 120 caract√®res", "autres_articles_mentions": [] } ] }`;

        const MAX_RETRIES = 3;
        let batchSuccess = false;

        for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
          try {
            if (attempt > 1) {
              const delay = attempt * 5000;
              console.log(`  ‚è≥ Batch ${batchNum} ‚Äî retry ${attempt}/${MAX_RETRIES} dans ${delay / 1000}s...`);
              await new Promise(resolve => setTimeout(resolve, delay));
            }

            const result = await openaiService.generateJSON(extractionPrompt, 24000);

            const rawList = normalizePoisFromResult(result);

            // Normalise les noms de champs (l'IA peut retourner name/nom, slug/poi_id, etc.)
            const poisList = rawList === null ? null : rawList.map((p: any) => ({
              poi_id: p.poi_id || p.id || p.slug || (p.nom || p.name || '').toLowerCase().replace(/[^a-z0-9]+/g, '_'),
              nom: p.nom || p.name || p.titre || p.label || '',
              type: p.type || p.category || p.categorie || 'autre',
              article_source: p.article_source || p.source || p.slug_source || '',
              url_source: p.url_source || p.url || p.source_url || '',
              mentions: p.mentions || p.mention || 'principale',
              raison_selection: p.raison_selection || p.reason || p.description || p.raison || '',
              autres_articles_mentions: p.autres_articles_mentions || p.other_articles || [],
            })).filter((p: any) => p.nom); // exclure les POIs sans nom

            if (poisList === null) {
              // Format non reconnu ‚Üí on logue et on retry
              console.warn(`  ‚ö†Ô∏è Batch ${batchNum} ‚Äî format JSON non reconnu, cl√©s: ${Object.keys(result || {}).join(', ')} ‚Äî retry`);
              throw new Error(`Format JSON non reconnu: ${JSON.stringify(result).substring(0, 200)}`);
            }

            // poisList peut √™tre vide (aucun POI dans ce batch) ‚Üí on marque succ√®s directement
            if (poisList.length === 0) {
              console.log(`  ‚úÖ Batch ${batchNum}: aucun POI dans ce batch (0 r√©sultat)`);
              previewBatches.push({
                batch_num: batchNum,
                total_batches: totalBatches,
                label: `Batch ${batchNum}/${totalBatches} ‚Äî multi-POI`,
                articles: validArticles.map((a: any) => ({ title: a.title, url: a.url || a.slug })),
                pois: [],
              });
              batchSuccess = true;
              break;
            }

            if (poisList.length > 0) {
              const enriched = poisList.map((poi: any) => {
                // Corriger article_source si l'IA a renvoy√© le titre du batch ou une valeur invalide
                const isBatchTitle = !poi.article_source ||
                  poi.article_source.startsWith('Batch ') ||
                  poi.article_source.startsWith('Lot de ');

                if (isBatchTitle || !poi.url_source) {
                  const matchByUrl = poi.url_source && articleByUrl[poi.url_source];
                  const matchByTitle = poi.article_source &&
                    validArticles.find((a: any) =>
                      a.title.toLowerCase().includes(poi.article_source.toLowerCase().substring(0, 20))
                    );
                  const fallback = matchByUrl || matchByTitle || validArticles[0];
                  return {
                    ...poi,
                    article_source: isBatchTitle ? fallback.title : poi.article_source,
                    url_source: poi.url_source && !isBatchTitle ? poi.url_source : (fallback.url || fallback.slug),
                  };
                }
                return poi;
              });
              const enrichedWithMode = enriched.map((p: any) => ({ ...p, _extraction_mode: 'multi' }));
              allRawPois.push(...enrichedWithMode);
              console.log(`  ‚úÖ Batch ${batchNum}${attempt > 1 ? ` (apr√®s ${attempt} tentatives)` : ''}: ${enrichedWithMode.length} POIs (total: ${allRawPois.length})`);

              // Sauvegarde interm√©diaire avec m√©tadonn√©es du batch pour la modale
              previewBatches.push({
                batch_num: batchNum,
                total_batches: totalBatches,
                label: `Batch ${batchNum}/${totalBatches} ‚Äî multi-POI`,
                articles: validArticles.map((a: any) => ({
                  title: a.title,
                  url: a.url || a.slug,
                  headings: extractHeadings(a.markdown || ''),
                })),
                pois: enrichedWithMode,
              });

              await db.collection('pois_generation_jobs').updateOne(
                { _id: new ObjectId(jobId) },
                { $set: { preview_pois: allRawPois, preview_batches: previewBatches, updated_at: new Date() } }
              );

              batchSuccess = true;
              break;
            }
          } catch (batchError: any) {
            console.error(`  ‚ùå Batch ${batchNum} ‚Äî tentative ${attempt}/${MAX_RETRIES}: ${batchError.message}`);
            if (attempt === MAX_RETRIES) {
              console.error(`  ‚õî Batch ${batchNum} abandonn√© apr√®s ${MAX_RETRIES} tentatives`);
            }
          }
        }

        if (!batchSuccess) {
          console.warn(`  ‚ö†Ô∏è Batch ${batchNum} ignor√© (${MAX_RETRIES} √©checs cons√©cutifs)`);
        }
      }

      if (allRawPois.length === 0) {
        throw new Error('Aucun POI extrait depuis les articles');
      }

      console.log(`üìä ${allRawPois.length} POIs bruts extraits ‚Äî en attente du d√©doublonnage manuel`);

      // 5. Marquer l'extraction comme termin√©e (sans d√©duplication ni sauvegarde dans pois_selection)
      // Le d√©doublonnage et la confirmation sont d√©clench√©s manuellement depuis l'interface
      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        {
          $set: {
            status: 'extraction_complete',
            raw_count: allRawPois.length,
            preview_pois: allRawPois,
            progress: null,
            updated_at: new Date(),
          },
        }
      );

      console.log(`‚úÖ [WORKER] Extraction termin√©e: ${allRawPois.length} POIs bruts pour guide ${guideId} ‚Äî en attente du d√©doublonnage manuel`);

      return reply.send({
        success: true,
        raw_count: allRawPois.length,
        articles_processed: total,
        status: 'extraction_complete',
      });

    } catch (error: any) {
      console.error(`‚ùå [WORKER] Erreur g√©n√©ration POIs:`, error);

      try {
        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { status: 'failed', error: error.message, progress: null, updated_at: new Date() } }
        );
      } catch (dbError) {
        console.error('Erreur mise √† jour statut job:', dbError);
      }

      return reply.status(500).send({
        error: 'Erreur lors de la g√©n√©ration des POIs',
        details: error.message,
      });
    }
  });

  /**
   * POST /workers/deduplicate-pois
   * Worker asynchrone (appel√© par QStash) pour d√©doublonner les POIs extraits.
   */
  fastify.post('/workers/deduplicate-pois', async (request, reply) => {
    const db = request.server.container.db;
    const { guideId, jobId } = request.body as { guideId: string; jobId: string };

    // ‚îÄ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    /** Normalise un nom pour comparaison : minuscules, sans accents, sans ponctuation */
    function normalizeName(s: string): string {
      return s.toLowerCase()
        .normalize('NFD').replace(/[\u0300-\u036f]/g, '')   // supprime les accents
        .replace(/[^a-z0-9 ]/g, ' ')
        .replace(/\s+/g, ' ')
        .trim();
    }

    /** Distance de Levenshtein entre deux cha√Ænes */
    function levenshtein(a: string, b: string): number {
      const m = a.length, n = b.length;
      const d: number[][] = Array.from({ length: m + 1 }, (_, i) =>
        Array.from({ length: n + 1 }, (_, j) => (i === 0 ? j : j === 0 ? i : 0))
      );
      for (let i = 1; i <= m; i++)
        for (let j = 1; j <= n; j++)
          d[i][j] = a[i-1] === b[j-1] ? d[i-1][j-1] : 1 + Math.min(d[i-1][j], d[i][j-1], d[i-1][j-1]);
      return d[m][n];
    }

    /**
     * Phase 1 : d√©duplication algorithmique pure, sans LLM.
     *
     * Fusionne les POIs dont :
     *  (a) le nom normalis√© est identique (doublons exacts)
     *  (b) la distance de Levenshtein entre noms normalis√©s est ‚â§ 2
     *  (c) l'un des noms normalis√©s est enti√®rement contenu dans l'autre
     *      ET les deux partagent le m√™me premier mot significatif (‚â• 4 chars)
     *
     * Pour chaque groupe, le POI conserv√© est celui qui poss√®de le nom le plus court
     * (le plus canonique) et les autres_articles_mentions sont consolid√©s.
     */
    function deduplicateAlgorithmically(pois: any[]): { pois: any[]; groups: string[][] } {
      const norms = pois.map(p => normalizeName(p.nom));
      const n = pois.length;
      const parent = Array.from({ length: n }, (_, i) => i);

      function find(i: number): number {
        if (parent[i] !== i) parent[i] = find(parent[i]);
        return parent[i];
      }
      function union(i: number, j: number) {
        parent[find(i)] = find(j);
      }

      for (let i = 0; i < n; i++) {
        for (let j = i + 1; j < n; j++) {
          const ni = norms[i], nj = norms[j];

          // (a) identiques
          if (ni === nj) { union(i, j); continue; }

          // (b) Levenshtein ‚â§ 2 (seuil adaptatif selon longueur)
          const maxLen = Math.max(ni.length, nj.length);
          const threshold = maxLen <= 10 ? 1 : 2;
          if (levenshtein(ni, nj) <= threshold) { union(i, j); continue; }

          // (c) l'un contient l'autre + m√™me premier mot significatif
          const firstWordI = ni.split(' ').find((w: string) => w.length >= 4) ?? '';
          const firstWordJ = nj.split(' ').find((w: string) => w.length >= 4) ?? '';
          if (firstWordI && firstWordI === firstWordJ && (ni.includes(nj) || nj.includes(ni))) {
            union(i, j);
          }
        }
      }

      // Construire les groupes
      const groups: Map<number, number[]> = new Map();
      for (let i = 0; i < n; i++) {
        const root = find(i);
        if (!groups.has(root)) groups.set(root, []);
        groups.get(root)!.push(i);
      }

      const fusedPois: any[] = [];
      const fusionGroups: string[][] = [];

      for (const members of groups.values()) {
        // Choisir le repr√©sentant : nom le plus court (le plus canonique)
        const sorted = members.sort((a, b) => pois[a].nom.length - pois[b].nom.length);
        const rep = pois[sorted[0]];

        // Consolider les mentions
        const allMentions = new Set<string>([
          ...(rep.autres_articles_mentions || []),
          ...sorted.slice(1).flatMap((idx: number) => pois[idx].autres_articles_mentions || []),
        ]);
        if (rep.article_source) allMentions.delete(rep.article_source);

        fusedPois.push({
          ...rep,
          autres_articles_mentions: Array.from(allMentions),
        });

        if (members.length > 1) {
          fusionGroups.push(members.map((idx: number) => pois[idx].nom));
        }
      }

      return { pois: fusedPois, groups: fusionGroups };
    }

    // ‚îÄ‚îÄ‚îÄ Worker ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    try {
      console.log(`üîÑ [WORKER-DEDUP] D√©doublonnage job ${jobId}`);

      const job = await db.collection('pois_generation_jobs').findOne({ _id: new ObjectId(jobId) });
      if (!job) throw new Error(`Job ${jobId} introuvable`);

      const rawPois: any[] = job.preview_pois || [];
      if (rawPois.length === 0) throw new Error('Aucun POI √† d√©doublonner');

      const guide = await db.collection('guides').findOne({ _id: new ObjectId(guideId) });
      const destination: string = guide?.destination ?? '';

      // ‚îÄ‚îÄ Phase 1 : d√©duplication algorithmique ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      const { pois: afterAlgo, groups: algoGroups } = deduplicateAlgorithmically(rawPois);
      const removedAlgo = rawPois.length - afterAlgo.length;
      console.log(`üî¢ [WORKER-DEDUP] Phase 1 algo : ${afterAlgo.length} POIs (${removedAlgo} fusionn√©s)`);
      if (algoGroups.length > 0) {
        algoGroups.slice(0, 20).forEach(g =>
          console.log(`  ‚Ü≥ fusionn√© : ${g.join(' | ')}`)
        );
      }

      // ‚îÄ‚îÄ Phase 2 : LLM ‚Äî d√©tection des groupes de doublons (sortie compacte) ‚îÄ
      //
      // Strat√©gie : au lieu de demander au LLM de retourner la liste compl√®te
      // d√©doublonn√©e (sortie ~400 POIs = troncature JSON), on lui demande
      // UNIQUEMENT les groupes de doublons identifi√©s. La sortie est alors
      // tr√®s courte (~50 groupes max) et ne peut pas √™tre tronqu√©e.
      // Le merge est ensuite fait programmatiquement.

      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) throw new Error('OPENAI_API_KEY non configur√©e');

      const { OpenAIService } = await import('../services/openai.service');
      const openaiService = new OpenAIService({ apiKey: openaiApiKey, model: 'gpt-5-mini', reasoningEffort: 'medium' });

      // Liste ultra-compacte : num√©ro + nom + type (‚âà 10 tokens/POI)
      const compactList = afterAlgo
        .map((p: any, i: number) => `${i}|${p.nom} (${p.type})`)
        .join('\n');

      const dedupGroupsPrompt = `Tu es un expert en consolidation de donn√©es touristiques.
Destination : ${destination}
Voici ${afterAlgo.length} POIs num√©rot√©s (format: num√©ro|nom (type)) :

${compactList}

MISSION : Identifie UNIQUEMENT les groupes de doublons ‚Äî des POIs qui d√©signent le M√äME lieu physique.

FUSIONNER si :
- Noms en langues diff√©rentes (ex: "Teide" = "Mount Teide" = "Pico del Teide")
- Variantes orthographiques / accents (ex: "Playa Fanabe" = "Playa de Fa√±ab√©")
- M√™me lieu avec/sans article ou pr√©cision g√©o (ex: "Aqualand" = "Aqualand Costa Adeje")

NE PAS FUSIONNER :
- Deux lieux distincts qui partagent un mot (ex : deux plages diff√©rentes)
- En cas de doute : ne pas fusionner

Pour chaque groupe, indique l'indice du POI √† CONSERVER (le plus pr√©cis / nom le plus riche).

Retourne UNIQUEMENT ce JSON (sans markdown) :
{
  "groupes": [
    { "indices": [3, 17, 42], "garder": 3, "raison": "m√™me lieu, 3 variantes" }
  ]
}

Si aucun doublon d√©tect√© : retourne { "groupes": [] }`;

      console.log(`ü§ñ [WORKER-DEDUP] Phase 2 LLM ‚Äî d√©tection groupes sur ${afterAlgo.length} POIs...`);
      const groupsResult = await openaiService.generateJSON(dedupGroupsPrompt, 4000);

      let dedupPois: any[] = [...afterAlgo];

      if (groupsResult.groupes && Array.isArray(groupsResult.groupes) && groupsResult.groupes.length > 0) {
        // Appliquer les fusions programmatiquement
        const toRemove = new Set<number>();

        for (const group of groupsResult.groupes) {
          const indices: number[] = group.indices ?? [];
          const keepIdx: number = group.garder ?? indices[0];

          if (!Number.isInteger(keepIdx) || keepIdx < 0 || keepIdx >= afterAlgo.length) continue;

          const keeper = afterAlgo[keepIdx];

          // Consolider les autres_articles_mentions dans le POI conserv√©
          const allMentions = new Set<string>(keeper.autres_articles_mentions || []);
          for (const idx of indices) {
            if (idx === keepIdx || !Number.isInteger(idx) || idx < 0 || idx >= afterAlgo.length) continue;
            const dup = afterAlgo[idx];
            if (dup.article_source && dup.article_source !== keeper.article_source) {
              allMentions.add(dup.article_source);
            }
            (dup.autres_articles_mentions || []).forEach((m: string) => allMentions.add(m));
            toRemove.add(idx);
          }

          // Mettre √† jour le keeper dans le tableau de r√©sultat
          dedupPois[keepIdx] = {
            ...keeper,
            autres_articles_mentions: Array.from(allMentions).filter(m => m !== keeper.article_source),
            alias_names: indices
              .filter(i => i !== keepIdx && Number.isInteger(i) && i >= 0 && i < afterAlgo.length)
              .map(i => afterAlgo[i].nom),
            dedup_confidence: group.raison ? 'certain' : 'probable',
          };
        }

        // Filtrer les doublons supprim√©s
        dedupPois = dedupPois.filter((_: any, i: number) => !toRemove.has(i));

        console.log(`‚úÖ [WORKER-DEDUP] Phase 2 : ${groupsResult.groupes.length} groupes d√©tect√©s, ${toRemove.size} doublons supprim√©s`);
        groupsResult.groupes.slice(0, 20).forEach((g: any) => {
          const names = (g.indices || []).map((i: number) => afterAlgo[i]?.nom ?? `#${i}`).join(' | ');
          console.log(`  ‚Ü≥ [${g.raison || ''}] ${names} ‚Üí garder: ${afterAlgo[g.garder]?.nom ?? g.garder}`);
        });
      } else {
        console.log(`‚úÖ [WORKER-DEDUP] Phase 2 : aucun doublon r√©siduel d√©tect√© par le LLM`);
      }

      const removedLLM = afterAlgo.length - dedupPois.length;
      const totalRemoved = rawPois.length - dedupPois.length;
      console.log(`‚úÖ [WORKER-DEDUP] Phase 2 LLM : ${dedupPois.length} POIs (${removedLLM} suppl√©mentaires)`);
      console.log(`‚úÖ [WORKER-DEDUP] TOTAL : ${dedupPois.length} POIs uniques (${totalRemoved} doublons sur ${rawPois.length})`);

      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        {
          $set: {
            status: 'dedup_complete',
            deduplicated_pois: dedupPois,
            dedup_count: dedupPois.length,
            dedup_algo_removed: removedAlgo,
            dedup_llm_removed: removedLLM,
            updated_at: new Date(),
          },
        }
      );

      return reply.send({ success: true, dedup_count: dedupPois.length, removed: totalRemoved, removed_algo: removedAlgo, removed_llm: removedLLM });

    } catch (error: any) {
      console.error(`‚ùå [WORKER-DEDUP] Erreur:`, error);
      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { $set: { status: 'extraction_complete', error_dedup: error.message, updated_at: new Date() } }
      ).catch(() => {});
      return reply.status(500).send({ error: error.message });
    }
  });

  /**
   * POST /workers/translate-json
   * Worker pour traduire un JSON (appel√© par QStash)
   */
  fastify.post('/workers/translate-json', async (request, reply) => {
    const db = request.server.container.db;
    const { jobId } = request.body as { jobId: string };

    try {
      console.log(`üöÄ [WORKER] Traduction JSON job ${jobId}`);

      if (!ObjectId.isValid(jobId)) {
        throw new Error('Job ID invalide');
      }

      // Charger le job
      const job = await db.collection('translation_jobs').findOne({
        _id: new ObjectId(jobId),
      });

      if (!job) {
        throw new Error('Job non trouv√©');
      }

      // Marquer comme "en cours"
      await db.collection('translation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { 
          $set: { 
            status: 'processing', 
            updated_at: new Date().toISOString() 
          } 
        }
      );

      // Traduire via ChatGPT
      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY non configur√©e');
      }

      const translator = new JsonTranslatorService(openaiApiKey);
      const result = await translator.translateJson(job.input_json);

      if (result.success) {
        // Succ√®s
        await db.collection('translation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          {
            $set: {
              status: 'completed',
              output_json: result.translatedJson,
              stats: result.stats,
              updated_at: new Date().toISOString(),
            },
          }
        );

        console.log(`‚úÖ [WORKER] Traduction termin√©e pour job ${jobId}`);
        return reply.send({ success: true, stats: result.stats });
      } else {
        // Erreur
        await db.collection('translation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          {
            $set: {
              status: 'failed',
              error: result.error,
              stats: result.stats,
              updated_at: new Date().toISOString(),
            },
          }
        );

        console.error(`‚ùå [WORKER] Traduction √©chou√©e pour job ${jobId}:`, result.error);
        return reply.status(500).send({
          error: 'Traduction √©chou√©e',
          details: result.error,
        });
      }
    } catch (error: any) {
      console.error(`‚ùå [WORKER] Erreur traduction job ${jobId}:`, error);

      // Marquer comme "failed"
      if (ObjectId.isValid(jobId)) {
        await db.collection('translation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          {
            $set: {
              status: 'failed',
              error: error.message,
              updated_at: new Date().toISOString(),
            },
          }
        );
      }

      return reply.status(500).send({
        error: 'Erreur lors de la traduction',
        details: error.message,
      });
    }
  });
}
