import { FastifyInstance } from 'fastify';
import { ObjectId } from 'mongodb';
import { PageRedactionService } from '../services/page-redaction.service';
import { JsonTranslatorService } from '../services/json-translator.service';

export async function workersRoutes(fastify: FastifyInstance) {
  /**
   * POST /workers/generate-page-content
   * Worker pour g√©n√©rer le contenu d'une page via IA
   * Appel√© par QStash de mani√®re asynchrone
   */
  fastify.post('/workers/generate-page-content', async (request, reply) => {
    const db = request.server.container.db;
    const { guideId, pageId } = request.body as { guideId: string; pageId: string };

    try {
      console.log(`üöÄ [WORKER] G√©n√©ration contenu page ${pageId}`);

      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY non configur√©e');
      }

      // G√©n√©rer le contenu via IA (avec retry automatique int√©gr√©)
      const redactionService = new PageRedactionService(db, openaiApiKey);
      const result = await redactionService.generatePageContent(guideId, pageId);

      // D√©terminer le statut √©ditorial selon le r√©sultat
      let statutEditorial = 'draft';
      let commentaire: string | undefined;

      if (result.status === 'success') {
        statutEditorial = 'generee_ia';
        commentaire = result.retryCount && result.retryCount > 0
          ? `G√©n√©r√© avec succ√®s apr√®s ${result.retryCount} tentative(s)`
          : undefined;
        console.log(`‚úÖ [WORKER] G√©n√©ration r√©ussie apr√®s ${result.retryCount || 0} retry(s)`);
      } else if (result.validationErrors && result.validationErrors.length > 0) {
        // Validation √©chou√©e apr√®s retries
        statutEditorial = 'non_conforme';
        const failedFieldsSummary = result.validationErrors
          .map((e) => `${e.field} (${e.errors.length} erreur(s))`)
          .join(', ');
        commentaire = `Validation √©chou√©e apr√®s ${result.retryCount || 0} tentative(s): ${failedFieldsSummary}`;
        console.error(`‚ùå [WORKER] Validation non conforme:`, commentaire);
      } else {
        // Autre erreur
        statutEditorial = 'non_conforme';
        commentaire = `Erreur IA: ${result.error || 'Erreur inconnue'}`;
        console.error(`‚ùå [WORKER] Erreur g√©n√©ration:`, commentaire);
      }

      // Sauvegarder le contenu g√©n√©r√© (m√™me si validation √©choue, pour permettre √©dition manuelle)
      await db.collection('pages').updateOne(
        { _id: new ObjectId(pageId) },
        { 
          $set: { 
            content: result.content,
            statut_editorial: statutEditorial,
            ...(commentaire && { commentaire_interne: commentaire }),
            updated_at: new Date().toISOString() 
          } 
        }
      );

      console.log(`‚úÖ [WORKER] Contenu sauvegard√© pour page ${pageId} (statut: ${statutEditorial})`);

      return reply.send({ 
        success: result.status === 'success', 
        pageId,
        fieldsGenerated: Object.keys(result.content).length,
        statutEditorial,
        retryCount: result.retryCount || 0,
        validationErrors: result.validationErrors
      });
    } catch (error: any) {
      console.error(`‚ùå [WORKER] Erreur fatale:`, error);
      
      // Marquer la page en erreur
      try {
        await db.collection('pages').updateOne(
          { _id: new ObjectId(pageId) },
          { 
            $set: { 
              statut_editorial: 'non_conforme',
              commentaire_interne: `Erreur worker: ${error.message}`,
              updated_at: new Date().toISOString() 
            } 
          }
        );
      } catch (dbError) {
        console.error('Erreur mise √† jour statut:', dbError);
      }

      return reply.status(500).send({ 
        error: 'Erreur lors de la g√©n√©ration',
        details: error.message 
      });
    }
  });

  /**
   * POST /workers/generate-pois
   * Worker pour g√©n√©rer les POIs depuis les articles WordPress via IA
   * Traitement par batch pour un recensement exhaustif, suivi d'un appel de d√©duplication.
   * Appel√© par QStash de mani√®re asynchrone
   */
  fastify.post('/workers/generate-pois', async (request, reply) => {
    const db = request.server.container.db;
    const { guideId, jobId } = request.body as { guideId: string; jobId: string };

    try {
      console.log(`üöÄ [WORKER] G√©n√©ration POIs par batch pour guide ${guideId}`);

      // Garde anti-doublon : refuser si un autre job est d√©j√† en cours pour ce guide
      const existingProcessing = await db.collection('pois_generation_jobs').findOne({
        guide_id: guideId,
        status: 'processing',
        _id: { $ne: new ObjectId(jobId) },
        // Ignorer les jobs bloqu√©s depuis plus de 30 minutes
        updated_at: { $gte: new Date(Date.now() - 30 * 60 * 1000) },
      });
      if (existingProcessing) {
        console.warn(`‚ö†Ô∏è [WORKER] Job ${existingProcessing._id} d√©j√† en cours pour guide ${guideId} ‚Äî abandon du doublon ${jobId}`);
        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { status: 'failed', error: 'Doublon : un job est d√©j√† en cours', updated_at: new Date() } }
        );
        return reply.send({ success: false, reason: 'duplicate' });
      }

      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { $set: { status: 'processing', updated_at: new Date() } }
      );

      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY non configur√©e');
      }

      const { OpenAIService } = await import('../services/openai.service');

      const openaiService = new OpenAIService({
        apiKey: openaiApiKey,
        model: 'gpt-5-mini',
        reasoningEffort: 'low',
      });

      // 1. Charger le guide
      const guide = await db.collection('guides').findOne({ _id: new ObjectId(guideId) });
      if (!guide) throw new Error('Guide non trouv√©');

      const destination: string = guide.destination;
      if (!destination) throw new Error('Aucune destination d√©finie pour ce guide');

      // 2. R√©cup√©rer les articles WordPress filtr√©s par destination
      const destinationFilter = { categories: { $regex: destination, $options: 'i' } };

      const articles = await db
        .collection('articles_raw')
        .find(destinationFilter)
        .project({ title: 1, slug: 1, markdown: 1, url: 1 })
        .toArray();

      if (articles.length === 0) {
        throw new Error(`Aucun article WordPress trouv√© pour la destination "${destination}"`);
      }

      console.log(`üìö ${articles.length} articles charg√©s pour "${destination}"`);

      // 3. Charger les prompts depuis la DB par leur ID unique
      const PROMPT_ID_EXTRACTION = process.env.PROMPT_ID_POI_EXTRACTION ?? 'prompt_1770544848350_9j5m305ukj';
      const PROMPT_ID_DEDUP      = process.env.PROMPT_ID_POI_DEDUP      ?? 'deduplication_POI_24022026';

      const promptExtractionDoc = await db.collection('prompts').findOne({ prompt_id: PROMPT_ID_EXTRACTION });
      if (!promptExtractionDoc) {
        throw new Error(`Prompt d'extraction POI non trouv√© (id: ${PROMPT_ID_EXTRACTION})`);
      }
      console.log(`üìã Prompt extraction: ${promptExtractionDoc.prompt_nom || promptExtractionDoc.prompt_id}`);

      // Prompt de d√©duplication (optionnel ‚Äî fallback int√©gr√© si absent)
      const promptDedupDoc = await db.collection('prompts').findOne({ prompt_id: PROMPT_ID_DEDUP });
      if (promptDedupDoc) {
        console.log(`üìã Prompt d√©dup: ${promptDedupDoc.prompt_nom || promptDedupDoc.prompt_id}`);
      } else {
        console.log(`üìã Prompt d√©dup: id "${PROMPT_ID_DEDUP}" non trouv√©, utilisation du prompt par d√©faut`);
      }

      // 4. Traitement par batch de 5 articles ‚Äî 1 appel OpenAI par batch
      const BATCH_SIZE = 5;
      const allRawPois: any[] = [];
      const total = articles.length;
      const totalBatches = Math.ceil(total / BATCH_SIZE);

      console.log(`üìä ${total} articles ‚Üí ${totalBatches} batches de ${BATCH_SIZE}`);

      for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
        const batchNum = batchIdx + 1;

        // V√©rifier √† chaque batch si le job a √©t√© annul√©
        const currentJob = await db.collection('pois_generation_jobs').findOne({ _id: new ObjectId(jobId) });
        if (!currentJob || currentJob.status === 'cancelled') {
          console.log(`üõë [WORKER] Job ${jobId} annul√© ‚Äî arr√™t √† batch ${batchNum}/${totalBatches}`);
          return reply.send({ success: false, reason: 'cancelled' });
        }

        const batchArticles = articles.slice(batchIdx * BATCH_SIZE, (batchIdx + 1) * BATCH_SIZE) as any[];
        const firstArticleNum = batchIdx * BATCH_SIZE + 1;

        console.log(`üîÑ Batch ${batchNum}/${totalBatches} ‚Äî articles ${firstArticleNum}-${firstArticleNum + batchArticles.length - 1}`);

        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { status: 'processing', progress: `Batch ${batchNum}/${totalBatches}`, updated_at: new Date() } }
        );

        // Filtrer les articles vides
        const validArticles = batchArticles.filter((a: any) => (a.markdown || '').trim());
        if (validArticles.length === 0) {
          console.log(`  ‚ö†Ô∏è Batch ${batchNum}: tous les articles sont vides, ignor√©`);
          continue;
        }

        // Construire le contenu group√© avec liste des titres + URLs en en-t√™te
        // pour que le mod√®le utilise les bons article_source dans sa r√©ponse
        const articlesIndex = validArticles
          .map((a: any, idx: number) => `${idx + 1}. "${a.title}" ‚Äî ${a.url || a.slug}`)
          .join('\n');

        const batchContent = validArticles
          .map((a: any, idx: number) =>
            `### Article ${idx + 1} : ${a.title}\nURL : ${a.url || a.slug}\n\n${a.markdown}`
          )
          .join('\n\n---\n\n');

        // Construire un article_source lookup pour la correction post-r√©ponse
        const articleByTitle: Record<string, any> = {};
        const articleByUrl: Record<string, any> = {};
        for (const a of validArticles) {
          articleByTitle[a.title.toLowerCase()] = a;
          if (a.url) articleByUrl[a.url] = a;
          if (a.slug) articleByUrl[a.slug] = a;
        }

        const extractionPrompt = openaiService.replaceVariables(promptExtractionDoc.texte_prompt, {
          SITE: guide.wpConfig?.siteUrl || '',
          DESTINATION: destination,
          ARTICLE_TITRE: `Lot de ${validArticles.length} articles (batch ${batchNum}/${totalBatches})`,
          ARTICLE_URL: '',
          ARTICLE_CONTENU: `Articles analys√©s :\n${articlesIndex}\n\n---\n\n${batchContent}`,
          LISTE_ARTICLES_POI: validArticles.map((a: any) => `- ${a.title} (${a.url || a.slug})`).join('\n'),
        });

        try {
          // max_tokens √©lev√© : un batch dense (ex: Teide) peut produire 30+ POIs √ó ~200 chars
          const result = await openaiService.generateJSON(extractionPrompt, 24000);

          if (result.pois && Array.isArray(result.pois)) {
            const enriched = result.pois.map((poi: any) => {
              // Corriger article_source si l'IA a renvoy√© le titre du batch ou une valeur invalide
              const isBatchTitle = !poi.article_source ||
                poi.article_source.startsWith('Batch ') ||
                poi.article_source.startsWith('Lot de ');

              if (isBatchTitle || !poi.url_source) {
                // Chercher l'article r√©el par correspondance de titre ou URL
                const matchByUrl = poi.url_source && (articleByUrl[poi.url_source]);
                const matchByTitle = poi.article_source &&
                  validArticles.find((a: any) =>
                    a.title.toLowerCase().includes(poi.article_source.toLowerCase().substring(0, 20))
                  );
                const fallback = matchByUrl || matchByTitle || validArticles[0];
                return {
                  ...poi,
                  article_source: isBatchTitle ? fallback.title : poi.article_source,
                  url_source: poi.url_source && !isBatchTitle ? poi.url_source : (fallback.url || fallback.slug),
                };
              }
              return poi;
            });
            allRawPois.push(...enriched);
            console.log(`  ‚úÖ Batch ${batchNum}: ${enriched.length} POIs (total: ${allRawPois.length})`);
          }
        } catch (batchError: any) {
          console.error(`  ‚ùå Batch ${batchNum} √©chou√©: ${batchError.message} ‚Äî on continue`);
        }
      }

      if (allRawPois.length === 0) {
        throw new Error('Aucun POI extrait depuis les articles');
      }

      console.log(`üìä Total POIs bruts extraits (avant d√©duplication): ${allRawPois.length}`);

      // 5. Appel de d√©duplication (exact + approchant)
      console.log(`üîÑ D√©duplication de ${allRawPois.length} POIs...`);

      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { $set: { status: 'processing', progress: 'D√©duplication', updated_at: new Date() } }
      );

      const poisJson = JSON.stringify(allRawPois, null, 0);

      const dedupPrompt = promptDedupDoc
        ? openaiService.replaceVariables(promptDedupDoc.texte_prompt, {
            DESTINATION: destination,
            NB_POIS: String(allRawPois.length),
            POIS_BRUTS_JSON: poisJson,
          })
        : `Tu es un expert en consolidation de bases de donn√©es g√©ographiques.

Voici ${allRawPois.length} POIs extraits article par article depuis des articles sur ${destination}.
Certains POIs apparaissent en double ou en triple (m√™me lieu dans plusieurs articles, variantes orthographiques, noms en diff√©rentes langues, etc.).

LISTE DES POIS BRUTS :
${poisJson}

T√¢che :
1. Identifie les doublons EXACTS (m√™me poi_id ou m√™me nom)
2. Identifie les doublons APPROCHANTS (m√™me lieu sous des appellations diff√©rentes, ex: "Teide" / "Pico del Teide" / "Mont Teide" / "Parc national du Teide")
3. Pour chaque groupe de doublons, conserve le POI le plus complet et fusionne :
   - "autres_articles_mentions" : r√©union de toutes les url_source / article_source
   - "article_source" / "url_source" : garde le plus repr√©sentatif (article d√©di√© > article liste)
4. Conserve TOUS les POIs uniques sans en supprimer

Retourne UNIQUEMENT un JSON valide : { "pois": [ ... ] }
(m√™me structure que l'entr√©e, apr√®s fusion)`;

      let finalPois: any[] = allRawPois;

      try {
        const dedupResult = await openaiService.generateJSON(dedupPrompt, 16000);
        if (dedupResult.pois && Array.isArray(dedupResult.pois)) {
          finalPois = dedupResult.pois;
          const removed = allRawPois.length - finalPois.length;
          console.log(`‚úÖ D√©duplication: ${finalPois.length} POIs uniques (${removed} doublons supprim√©s)`);
        } else {
          console.warn('‚ö†Ô∏è D√©duplication: r√©ponse inattendue, on garde les POIs bruts');
        }
      } catch (dedupError: any) {
        console.error(`‚ùå D√©duplication √©chou√©e: ${dedupError.message} ‚Äî on conserve les POIs bruts`);
      }

      // 6. Normaliser les POIs
      const pois: any[] = finalPois.map((poi: any) => ({
        poi_id: poi.poi_id,
        nom: poi.nom,
        type: poi.type,
        source: 'article',
        article_source: poi.article_source,
        url_source: poi.url_source || '',
        raison_selection: poi.raison_selection,
        autres_articles_mentions: poi.autres_articles_mentions || [],
      }));

      // 7. Sauvegarder la s√©lection
      const now = new Date();
      await db.collection('pois_selection').updateOne(
        { guide_id: guideId },
        {
          $set: { guide_id: guideId, pois, updated_at: now },
          $setOnInsert: { created_at: now },
        },
        { upsert: true }
      );

      // 8. Marquer le job comme "completed"
      await db.collection('pois_generation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        {
          $set: {
            status: 'completed',
            count: pois.length,
            raw_count: allRawPois.length,
            progress: null,
            updated_at: new Date(),
          },
        }
      );

      console.log(`‚úÖ [WORKER] ${pois.length} POIs sauvegard√©s pour guide ${guideId} (${allRawPois.length} extraits, ${allRawPois.length - pois.length} doublons supprim√©s)`);

      return reply.send({
        success: true,
        count: pois.length,
        raw_count: allRawPois.length,
        articles_processed: total,
      });

    } catch (error: any) {
      console.error(`‚ùå [WORKER] Erreur g√©n√©ration POIs:`, error);

      try {
        await db.collection('pois_generation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          { $set: { status: 'failed', error: error.message, progress: null, updated_at: new Date() } }
        );
      } catch (dbError) {
        console.error('Erreur mise √† jour statut job:', dbError);
      }

      return reply.status(500).send({
        error: 'Erreur lors de la g√©n√©ration des POIs',
        details: error.message,
      });
    }
  });

  /**
   * POST /workers/translate-json
   * Worker pour traduire un JSON (appel√© par QStash)
   */
  fastify.post('/workers/translate-json', async (request, reply) => {
    const db = request.server.container.db;
    const { jobId } = request.body as { jobId: string };

    try {
      console.log(`üöÄ [WORKER] Traduction JSON job ${jobId}`);

      if (!ObjectId.isValid(jobId)) {
        throw new Error('Job ID invalide');
      }

      // Charger le job
      const job = await db.collection('translation_jobs').findOne({
        _id: new ObjectId(jobId),
      });

      if (!job) {
        throw new Error('Job non trouv√©');
      }

      // Marquer comme "en cours"
      await db.collection('translation_jobs').updateOne(
        { _id: new ObjectId(jobId) },
        { 
          $set: { 
            status: 'processing', 
            updated_at: new Date().toISOString() 
          } 
        }
      );

      // Traduire via ChatGPT
      const openaiApiKey = process.env.OPENAI_API_KEY;
      if (!openaiApiKey) {
        throw new Error('OPENAI_API_KEY non configur√©e');
      }

      const translator = new JsonTranslatorService(openaiApiKey);
      const result = await translator.translateJson(job.input_json);

      if (result.success) {
        // Succ√®s
        await db.collection('translation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          {
            $set: {
              status: 'completed',
              output_json: result.translatedJson,
              stats: result.stats,
              updated_at: new Date().toISOString(),
            },
          }
        );

        console.log(`‚úÖ [WORKER] Traduction termin√©e pour job ${jobId}`);
        return reply.send({ success: true, stats: result.stats });
      } else {
        // Erreur
        await db.collection('translation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          {
            $set: {
              status: 'failed',
              error: result.error,
              stats: result.stats,
              updated_at: new Date().toISOString(),
            },
          }
        );

        console.error(`‚ùå [WORKER] Traduction √©chou√©e pour job ${jobId}:`, result.error);
        return reply.status(500).send({
          error: 'Traduction √©chou√©e',
          details: result.error,
        });
      }
    } catch (error: any) {
      console.error(`‚ùå [WORKER] Erreur traduction job ${jobId}:`, error);

      // Marquer comme "failed"
      if (ObjectId.isValid(jobId)) {
        await db.collection('translation_jobs').updateOne(
          { _id: new ObjectId(jobId) },
          {
            $set: {
              status: 'failed',
              error: error.message,
              updated_at: new Date().toISOString(),
            },
          }
        );
      }

      return reply.status(500).send({
        error: 'Erreur lors de la traduction',
        details: error.message,
      });
    }
  });
}
